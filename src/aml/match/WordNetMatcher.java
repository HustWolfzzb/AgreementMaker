/******************************************************************************
* Copyright 2013-2016 LASIGE                                                  *
*                                                                             *
* Licensed under the Apache License, Version 2.0 (the "License"); you may     *
* not use this file except in compliance with the License. You may obtain a   *
* copy of the License at http://www.apache.org/licenses/LICENSE-2.0           *
*                                                                             *
* Unless required by applicable law or agreed to in writing, software         *
* distributed under the License is distributed on an "AS IS" BASIS,           *
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    *
* See the License for the specific language governing permissions and         *
* limitations under the License.                                              *
*                                                                             *
*******************************************************************************
* Matches Ontologies by finding literal full-name matches between their       *
* Lexicons after extension with the WordNet.                                  *
*                                                                             *
* @author Daniel Faria                                                        *
******************************************************************************/
package aml.match;

import java.util.HashSet;
import java.util.Set;
import java.util.Vector;

import aml.AML;
import aml.ext.LexiconExtender;
import aml.knowledge.WordNet;
import aml.ontology.Lexicon;
import aml.settings.EntityType;
import aml.settings.InstanceMatchingCategory;
import aml.settings.LexicalType;
import aml.util.StringParser;

public class WordNetMatcher implements PrimaryMatcher, LexiconExtender
{
	
//Attributes

	private static final String DESCRIPTION = "Matches entities that have one or more exact\n" +
			  								  "String matches between a Lexicon entry and a\n" +
			  								  "WordNet synonym or between WordNet synonyms";
	private static final String NAME = "WordNet Matcher";
	private static final EntityType[] SUPPORT = {EntityType.CLASS,EntityType.INDIVIDUAL,EntityType.DATA,EntityType.OBJECT};
	//The WordNet class
	private WordNet wn;
	//The type of lexical entry generated by this LexiconExtender
	private final LexicalType TYPE = LexicalType.EXTERNAL_MATCH;
	//The source of this LexiconExtender
	private final String SOURCE = "WordNet";
	//The confidence score of WordNet
	private final double CONFIDENCE = 0.9;
	
//Constructors

	/**
	 * Constructs a new WordNetMatcher
	 */
	public WordNetMatcher()
	{
		wn = new WordNet();
	}

//Public Methods

	@Override
	public void extendLexicons()
	{
		System.out.println("Extending Lexicons with WordNet Matcher");
		long time = System.currentTimeMillis()/1000;
		AML aml = AML.getInstance();
		for(EntityType e : EntityType.values())
		{
			extendLexicon(aml.getSource().getLexicon(),e,0.0);
			extendLexicon(aml.getTarget().getLexicon(),e,0.0);
		}
		time = System.currentTimeMillis()/1000 - time;
		System.out.println("Finished in " + time + " seconds");
	}
	
	@Override
	public String getDescription()
	{
		return DESCRIPTION;
	}

	@Override
	public String getName()
	{
		return NAME;
	}

	@Override
	public EntityType[] getSupportedEntityTypes()
	{
		return SUPPORT;
	}
	
	@Override
	public Alignment match(EntityType e, double thresh) throws UnsupportedEntityTypeException
	{
		//检查实体类型是否被支持，包括，类，实例，数据属性，对象属性
		checkEntityType(e);
		System.out.println("Running WordNet Matcher");
		long time = System.currentTimeMillis()/1000;
		//获取系统的实例
		AML aml = AML.getInstance();
		// 得到aml中的source的词汇库
		Lexicon source = new Lexicon(aml.getSource().getLexicon());
		// 得到aml中的target的词汇库
		Lexicon target = new Lexicon(aml.getTarget().getLexicon());
		// 扩展词汇库
		extendLexicon(source,e,thresh);
		extendLexicon(target,e,thresh);
		// 扩展词汇库完成之后，再调用默认的match函数
		Alignment a = match(source,target,e,thresh);
		time = System.currentTimeMillis()/1000 - time;
		System.out.println("Finished in " + time + " seconds");
		return a;
	}
	
//Private Methods

	private void checkEntityType(EntityType e) throws UnsupportedEntityTypeException
	{
		boolean check = false;
		for(EntityType t : SUPPORT)
		{
			if(t.equals(e))
			{
				check = true;
				break;
			}
		}
		if(!check)
			throw new UnsupportedEntityTypeException(e.toString());
	}
	
	private void extendLexicon(Lexicon l, EntityType e, double thresh)
	{
		//Get the original Lexicon names into a Vector since the
		//Lexicon will be extended during the iteration (otherwise
		//we'd get a concurrentModificationException)
		//提取出传入的词汇库的所有的名字
		Vector<String> names = new Vector<String>(l.getNames(e));
		//Iterate through the original Lexicon names
		// 对每一个提取出的词汇进行挨个的解析
		for(String s : names)
		{
			//We don't match formulas to WordNet
			// 如果WordNet中都乜有这个词，那么，让他滚
			if(StringParser.isFormula(s))
				continue;
			//Find all wordForms in WordNet for each full name
			// 从这个名字出发的所有的同义词都给获取出来
			HashSet<String> wordForms = wn.getAllNounWordForms(s);
			//If there aren't any, break the name into words
			//(if it is a multi-word name) and look for wordForms
			//of each word
			//如果这个名字获取不到同义词，那么进行拆解，根据空格来
			if(wordForms.size() == 0 && s.contains(" "))
			{
				String[] words = s.split(" ");
				for(String w : words)
				{
					// 分割之后如果长度小于3，那么跳过，否则就按照前面的步骤获取同义词
					if(w.length() < 3)
						continue;
					HashSet<String> wf = wn.getAllNounWordForms(w);
					if(wf.size() == 0)
						continue;
					for(String f : wf)
						// 对每一个同义词，如果它不含有空格，那么就直接用这个词代替掉名字中原来的无法获取同义词的部分放到名字里面并且加入同义词中
						if(!f.contains(" "))
							wordForms.add(s.replace(w, f));
				}
			}
			//If there are still no wordForms, proceed to next name
			//r如果这样还没法找到同义词，那么就跳出来
			if(wordForms.size() == 0)
				continue;
			// 找到了同义词，就用0.9-同义词数量/100
			double conf = CONFIDENCE - 0.01*wordForms.size();
			//如果得到的置信度低于阈值，就抛弃，否则就
			if(conf < thresh)
				continue;
			// 如果s是外在的（？？？），那么就获取它在Lex中所有对应的同义词的index
			Set<Integer> terms = l.getInternalEntities(e,s);
			//Add each term with the name to the extension Lexicon
			// 将每个得到的name 扩展到 词汇库中去
			for(Integer i : terms)
			{
				//对每一个index，都计算其相应的相似度权重，乘以置信度，得到一个相似度，与阈值进行匹配
				double weight = conf * l.getWeight(s, i);
				if(weight < thresh)
					continue;
				// 如果权重达标，那么就把换这个加入到当前的词汇库中去，标记为match
				for(String w : wordForms)
					l.add(i, w, "en", TYPE, SOURCE, weight);
			}
		}
	}
	
	//Matches two Lexicons
	private Alignment match(Lexicon source, Lexicon target, EntityType e, double thresh)
	{
		AML aml = AML.getInstance();
		Alignment maps = new Alignment();
		// 从source这里得到所有待匹配的名字
		Set<String> names = source.getNames(e);
		for(String s : names)
		{
			//Get all term indexes for the name in both ontologies
			// 获取所有的此类型的同名的实体的index
			Set<Integer> sIndexes = source.getEntities(e,s);
			Set<Integer> tIndexes = target.getEntities(e,s);
			if(tIndexes == null)
				continue;
			//Otherwise, match all indexes
			// 如果存在目标index，那么就进行m x n 的配对
			for(Integer i : sIndexes)
			{
				//如果是实例，而又在源实例集中找不到，就不进行配对
				if(e.equals(EntityType.INDIVIDUAL) && !aml.isToMatchSource(i))
					continue;
				//Get the weight of the name for the term in the smaller lexicon
				// 获取小的词汇库中的修正系数
				double weight = source.getCorrectedWeight(s, i);
				Set<String> sSources = source.getSources(s, i);
				for(Integer j : tIndexes)
				{
					if(e.equals(EntityType.INDIVIDUAL) && (!aml.isToMatchTarget(j) ||
							(aml.getInstanceMatchingCategory().equals(InstanceMatchingCategory.SAME_CLASSES) &&
							!aml.getRelationshipMap().shareClass(i,j))))
						continue;
					Set<String> tSources = target.getSources(s, j);
					//We only consider matches involving at least one WordNet synonym
					//and not envolving any external synonyms
					// 只考虑涉及至少一个WordNet同义词的部分，不接受任何外部同义词
					boolean check = (sSources.contains(SOURCE) && tSources.contains(SOURCE)) ||
							(sSources.contains(SOURCE) && tSources.contains("")) ||
							(sSources.contains("") && tSources.contains(SOURCE));
					if(!check)
						continue;

					//Get the weight of the name for the term in the larger lexicon
					// 获取大的词汇库中的修正系数
					double similarity = target.getCorrectedWeight(s, j);
					//Then compute the similarity, by multiplying the two weights
					similarity *= weight;
					//If the similarity is above threshold add the mapping
					if(similarity >= thresh)
						maps.add(new Mapping(i, j, similarity));
				}
			}
		}
		return maps;	
	}
}